{
    "batch_size": 16,
    "gradient_accumulation_steps": 8,
    "learning_rate": 3.7716157190923305e-05,
    "weight_decay": 0.07335929702927076,
    "epochs": 4,
    "seed": 75
}